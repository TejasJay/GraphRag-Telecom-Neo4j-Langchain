{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b27142e6",
   "metadata": {},
   "source": [
    "# üîß Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5704f262",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U numpy==1.26.4 pandas scikit-learn     langchain langchain-openai langchain-community     qdrant-client neo4j\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5b641e",
   "metadata": {},
   "source": [
    "## üõ† Fix numpy bool compatibility (temporary workaround)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9feab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "if not hasattr(np, 'bool'):\n",
    "    np.bool = bool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c947b8",
   "metadata": {},
   "source": [
    "## üìÅ Load Telecom Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b7bb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "templates_df = pd.read_csv('templates.csv')\n",
    "projects_df = pd.read_csv('projects_tasks.csv')\n",
    "templates_df.head(), projects_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0498a5",
   "metadata": {},
   "source": [
    "## üß† Neo4j Graph Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e6baa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "uri = \"bolt://graph-neo4j:7687\"\n",
    "auth = (\"neo4j\", \"password\")\n",
    "driver = GraphDatabase.driver(uri, auth=auth)\n",
    "driver.verify_connectivity()\n",
    "print(\"‚úÖ Neo4j connection successful!\")\n",
    "\n",
    "cypher_query = '''\n",
    "MERGE (p:Project {id: $project_id})\n",
    "MERGE (t:Task {id: $task_id, name: $task_name, status: $status, risk: $risk})\n",
    "MERGE (tpl:Template {id: $template_id})\n",
    "MERGE (p)-[:HAS_TASK]->(t)\n",
    "MERGE (t)-[:USES_TEMPLATE]->(tpl)\n",
    "'''\n",
    "\n",
    "def insert_row(tx, row):\n",
    "    tx.run(cypher_query, \n",
    "           project_id=row['project_id'],\n",
    "           task_id=row['task_id'],\n",
    "           task_name=row['task_name'],\n",
    "           status=row['status'],\n",
    "           risk=row['risk'],\n",
    "           template_id=row['template_id'])\n",
    "\n",
    "with driver.session() as session:\n",
    "    for i, row in projects_df.iterrows():\n",
    "        session.write_transaction(insert_row, row)\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Inserted {i} records...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0e80df",
   "metadata": {},
   "source": [
    "## üì¶ Vector Store Ingestion to Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c616dc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Qdrant\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'your-api-key'  # Or use a mounted .env and dotenv\n",
    "\n",
    "qdrant = QdrantClient(host=\"vector-qdrant\", port=6333)\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "texts = [f\"{row.template_name} - Roles: {row.required_roles}\" for _, row in templates_df.iterrows()]\n",
    "metadata = templates_df.to_dict(orient='records')\n",
    "\n",
    "vectorstore = Qdrant.from_texts(\n",
    "    texts, embedding=embedding_model, metadatas=metadata,\n",
    "    collection_name=\"telecom_templates\", qdrant_client=qdrant\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0cb4d2",
   "metadata": {},
   "source": [
    "## üß† Agent with Graph + Vector RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339196cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.graph_qa.cypher import GraphCypherQAChain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.graphs import Neo4jGraph\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4\")\n",
    "graph = Neo4jGraph(url=uri, username=\"neo4j\", password=\"password\")\n",
    "\n",
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    llm, graph=graph, verbose=True, allow_dangerous_requests=True\n",
    ")\n",
    "\n",
    "retriever_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm, retriever=vectorstore.as_retriever(), verbose=True\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    Tool(name=\"Graph QA\", func=cypher_chain.run, description=\"Use for schema and task relationships\"),\n",
    "    Tool(name=\"Template Lookup\", func=retriever_chain.run, description=\"Use for template descriptions\")\n",
    "]\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdd3996",
   "metadata": {},
   "source": [
    "## üîç Ask Questions to Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80c3a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"What are the risk levels in project PROJ-00001 and what template does it use?\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
